{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_Train_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Get the Git Repo\n",
        "\n",
        "This is forked repo from the darknet.\n",
        "Modifications are made for this project."
      ],
      "metadata": {
        "id": "BDhPCz0NUcyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzO12zmlIynK"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/alekhyaramarao/darknet.git\n",
        "%cd darknet\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2:\n",
        "For the purpose of reading data use google drive.\n",
        "*As adding data in the colab runtime will be repeated and cost ineffective.*\n"
      ],
      "metadata": {
        "id": "KFwUnWyuUzxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to the google drive\n",
        "from google.colab import drive\n",
        "# drive.mount('/content.gdrive')\n",
        "drive._mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv6msxcXRW_T",
        "outputId": "fc41854b-fd2a-4fee-9545-6e15df55da5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 3: Data Preprocessing\n",
        "\n",
        "# ***Skip to Step 7 if not training***\n",
        "\n",
        "The below code will execute the following files:\n",
        "\n",
        "1. **bosch_to_pascal.py** - Converts the bosch data to VOC format and stores it in the given path.\n",
        "2.   **make_xml_list.py** - Read all the xml files from the given path and create \"bosch_traffic_light_xmls_list.txt\"\n",
        "3.   **bosch_voc_to_yolo_converter.py** - Reads the bosch_traffic_lights_xmls_list.txt and converts the bosch VOC data to YOLO type by creating individual .txt file for every image in the given path. *( For this framework, ensure that the path given to store the .txt files is the same where the images are store)*\n",
        "4. **train_test_split.py** - This will create a split of the given percentage between train and validation data.\n",
        "(If you are running for just generating a result file for the input to classification training, then no need to split)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0a2c14EYVLrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "% cd traffic-lights/\n",
        "! python bosch_to_pascal.py train.yaml /content/drive/MyDrive/Dataset/rgb/train/traffic_light_xmls/\n",
        "! python make_xml_list.py /content/drive/MyDrive/Dataset/rgb/train/traffic_light_xmls/\n",
        "! python bosch_voc_to_yolo_converter.py /content/drive/MyDrive/Dataset/rgb/train/traffic_light_images/ bosch_traffic_light_xmls_list.txt /content/drive/MyDrive/Dataset/rgb/train/traffic_light_images/\n",
        "! python train_test_split.py traffic_lights.txt 0.2\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "LUYYEWjzSNUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Get Weights\n",
        "(Only required if training and for the first time)\n",
        "If continuing training then use the previously found best model weights and start training from there\n"
      ],
      "metadata": {
        "id": "r-LQ6BbW2B54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get yolov4 weights\n",
        "#only run this if starting the training from the scratch. If you have already trained and want to train from where you left off, then use those weights. \n",
        "! wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n"
      ],
      "metadata": {
        "id": "Jlvmvkvw0wZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Install Pre-requisites"
      ],
      "metadata": {
        "id": "Usidmr_i2UCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install all the apps which are required\n",
        "!apt install ffmpeg libopencv-dev libgtk-3-dev python-numpy python3-numpy libdc1394-22 libdc1394-22-dev libjpeg-dev libtiff5-dev libavcodec-dev libavformat-dev libswscale-dev libxine2-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libv4l-dev libtbb-dev qtbase5-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils unzip"
      ],
      "metadata": {
        "id": "mOdrto0K04Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Start Training"
      ],
      "metadata": {
        "id": "cLeXIBDG1h3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd ..\n",
        "%cd /content/darknet/\n",
        "! ./darknet detector train traffic-lights/voc-bosch.data traffic-lights/yolov4-tiny-custom.cfg traffic-lights/yolov4-tiny-custom_best.weights -dont_show -map"
      ],
      "metadata": {
        "id": "pRjMrXsQ1dcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Test\n",
        "**Skip steps 3-6 if only testing the model**\n",
        "Once trained use the best weights and input video/Image to test your trained model"
      ],
      "metadata": {
        "id": "p4xUOMrh2e9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! ./darknet detector demo voc-bosch.data yolov4-tiny-custom.cfg yolov4-tiny-custom_best.weights test_video.mp4 -dont_show -out_filename res.mp4\n"
      ],
      "metadata": {
        "id": "kqPVD0bz6raI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! ./darknet detector test voc-bosch.data yolov4-tiny-custom.cfg yolov4-tiny-custom_best.weights 39418.png -dont_show"
      ],
      "metadata": {
        "id": "Jur1eed_qcU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Generate Json file with predicted bounding box information using trained weights\n",
        "\n",
        "Pass a .txt file with the path to images\n",
        "\n",
        "***This is required as entry point for classification network***\n",
        "\n",
        "Follow Step 3 to create .txt file with all images from the dataset."
      ],
      "metadata": {
        "id": "VqrupK4YI8UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ./darknet detector test traffic-lights/voc-bosch.data traffic-lights/yolov4-tiny-custom.cfg traffic-lights/yolov4-tiny-custom_best.weights -ext_output -dont_show -out result.json < traffic-lights/traffic_lights.txt"
      ],
      "metadata": {
        "id": "jv9vFgjjOeL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9AqAgwZ7ZGU5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}